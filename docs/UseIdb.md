# 关于Idb
<!-- 2025-03-04 -->
## 分为三个store，都以id为key
1. book_metadata: 存放name,bookMark,readRecord
2. book_file: 存放源文件
3. book_parseData: 存放paraArr,chapterArr,charSet,heightArr,客户端解析后的数据
## 参与同步的库
1. meatData 轻量 全量同步就好
2. bookFile 固定 占用大 缓存加唯一标识减少压力

`server`暂时使用的Nedb(我感觉不太好用，之后应该会换)，目前最大的问题就是跨设备同步方案，因为服务器资源有限，需要尽量节省
稍微写点想法
1. 与`client`不同，仅仅存储metaData,谨慎存储bookFile
2. 现在假设有100本书，每个5m，现有的同步方案绝对会崩掉。

假设现在没有链接到`server`，存有100本书，突然链接的时候，如果发起100次`createBook`，那又完蛋了，所以应该考虑创建的时候仅包含`{id,name，hash}`，这个`hash`就是`bookFile`计算出来的唯一值，用来区分相同的文件，减少占用。
如果参与同步的仅仅是一个很小的对象：`{id,name,hash}`，那我完全可以完成表面上的同步，也就是`meatData`，就算是100本，不过kb级别，完成同步在毫秒内。
如果加一个一个更新策略概念（我自己瞎起的），我的`metaData`是实时更新，`bookFile`是懒更新。
1. 当我新增一本书，我仅仅上传`meatData`,在网络通畅的情况下再上传`bookFile`
2. 当我删除一本书，同样只删除`metaData`,短时间内可以保留存在`server`的`bookFile`
3. 更新的话，就是常规的更新`meatData`（虽然现在没有任何`metaData`）

当100本书的数据都上传成功了，另一个全新的设备加入进来，获取元数据，然后渲染书架。当然，它没有取得任何一本书的实际内容，仅当它点击一本书的时候，调用`getBookFile`，随后就是常规的客户端解析，存到`indexDb`的`book_parseData`,网络请求获取会稍慢一点，解析还要花上一些时间，这挺不好的。
自然而然地，我想到了分块。比如我拆分一个txt为`100kb/块`，5mb就是50个块，当我点击图书的时候，我暂时只需要获取某个分块的数据并解析，假设原本传输加解析需要`10s+2s` ,分块后只需要`240ms`，这确实是一个不错的选择，前提是我能把同步功能写好。
当然渲染也不能拉下，现有的渲染完全没考虑服务端的概念，默认书籍都在本地且完全解析了。所以渲染也可以考虑额外写一个支持分块的渲染？我本地传入的书籍，还是可以继续用现有的，而那些网络上的，依靠分块进行同步的书籍，则使用新写的分块渲染器。

总的来说，需要干以下几件事情：
1. 数据库表结构调整，划分为三个，`meatData`,`file`,`parseData`
2. `file`唯一性区分，id与hash可以合并为一个，不同文件对应不同hash
3. 完善同步功能，至少保证增删改查以及冲突解决
4. 分块策略构思
5. 分块渲染构思